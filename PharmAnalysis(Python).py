# -*- coding: utf-8 -*-
"""BAX452_MLFinalProject_Group28.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GFAiRM3v-w5pVPjnlVg8sQXHaIN994JI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random

from google.colab import files
uploaded = files.upload()

medicines = pd.read_csv('Final_Project_1mg_medicines.csv')
medicines_copy = medicines

"""# Data Cleaning

There are 12,936 medicines in the dataset with 9 descriptors.
According to the FDA, most medicines available can be classified into 40 categories.
"""

from google.colab import files
uploaded = files.upload()

drug_categories = pd.read_csv('DrugCategories.csv',header=None)
drug_categories = drug_categories.drop([2],axis=1)
drug_categories.columns =['Drug', 'Description']

drug_categories.dtypes

drug_categories

medicines.shape

medicines.dtypes

medicines.isna().sum()

medicines = medicines.drop_duplicates('Name', keep='last')

medicines.shape

medicines['Price'].value_counts()

medicines['Price'] = medicines['Price'].replace({' Not found ': np.nan})
medicines['Price'] = medicines['Price'].astype('float')
medicines['Price'].value_counts()

medicines2 = medicines.drop(['interactingDrug','Side Effects'], axis=1)

medicines2.dtypes

medicines2

medicines2['manufacturer'] = medicines2['manufacturer'].apply(lambda x: x.replace('}', ''))
medicines2['nonProprietaryName'] = medicines2['nonProprietaryName'].apply(lambda x: x.replace('+', ','))
medicines2['activeIngredient'] = medicines2['activeIngredient'].apply(lambda x: x.replace('+', ','))
medicines2['mechanismOfAction'] = medicines2['mechanismOfAction'].str.replace('[', '').str.replace(']', '')

medicines2 = medicines2.drop(['Substitute'], axis=1)

import re
therapeutic_class = []

for entry in medicines2['Factbox']:
    match = re.search(r"'Therapeutic Class': '(.+?)'", entry)
    if match:
        therapeutic_class.append(match.group(1))
    else:
        therapeutic_class.append(None)

therapeutic_class

medicines2['therapeutic_class'] = therapeutic_class
medicines2['therapeutic_class'] = medicines2['therapeutic_class'].replace({'\'': ''}, regex=True)

medicines2 = medicines2.drop(['Factbox'],axis=1)
medicines2

"""Exploring different uses/categories of medicines"""

len(medicines2['Uses'].value_counts())

medicines2['Uses'].value_counts()

medicines2['Uses'].value_counts().head(100).plot(kind = 'bar')
plt.rcParams["figure.figsize"] = (60,30)

medicines2['Uses'].value_counts().head(10).sum()/medicines2['Uses'].value_counts().sum()

"""Checking average price of medicine by usage

"""

result = medicines2.groupby('Uses')['Price'].mean()
result.dropna().sort_values(ascending = False)

result.dropna().sort_values(ascending = False).head(100).plot(kind = 'bar')
plt.rcParams["figure.figsize"] = (50,20)

len(medicines2['therapeutic_class'].value_counts())

medicines2['therapeutic_class'].value_counts()

medicines2['therapeutic_class'].value_counts().plot(kind = 'bar')
plt.rcParams["figure.figsize"] = (40,20)

medicines2

"""Aim 1: To cluster/label medicines according to the 40 categories listed by the FDA.

Aim 2: To build model which predicts price of medicines based on its details.

Features to be used: activeIngredient, Name, Price, Dosage Form, therapeutic_class, Mechanism of Action, Uses, benefits, description, product info. Columns Description, Product Info, and Benefits to be concatenated.
"""

medicines_final = medicines2.drop(['manufacturer','nonProprietaryName','Workings'],axis=1)
# Workings column is mostly a duplicate of the Mechanism of Action column
medicines_final

medicines_final['Product Info'].fillna('', inplace=True)
medicines_final['Combined_desc'] = medicines_final['Product Info'] + medicines_final['Description'] + medicines_final['Benefits']
medicines_final

medicines_final.iloc[0,10]

medicines_final.isna().sum()

medicines_final = medicines_final.drop(['Product Info','Description','Benefits'],axis=1)
medicines_final

medicines_final.dtypes

medicines_final.isna().sum()

"""Now we can work with the medicines_final dataset

# Labeling Medicines according to FDA
"""

medicines_final

drug_categories

"""Since we do not have any information on the correct labels for the medicines, we will have to employ Unsupervised learning methods.

AIM 1: Classifying medicines according to categories listed by the FDA.

Method 1: By measuring cosine similarity between concatenated embeddings of medicine information, description, and beneifts with embeddings of Drug Categories.

Method 2: Performing K Means Clustering (K=40) by concatenating embeddings of Active Ingredients, Therapeutic Class, and Combined Description for each medicine, creating vectors of dimension 600. Further generating average mebeddings for 'Types of Uses' corresponding to each cluster and then calculating cosine similarity with Drug Catgory embeddings.

Method 3: By performing Topic Modeling through Latent Dirichlet Analysis on combined text from product information, description, and benefits. Identifying which topic does the combined document have the highest probability of belonging to, extracting the top 20 words, generating their embeddings, and building a cosine similarity matrix with embeddings of Drug Categories.

AIM 2: Finding substitute medicines for each medicine.

Method: Generating embeddings for combined textual description of product and comparing cosine similiarity with other medicines in the dataset.

AIM 3: Building a Price Prediction Model

Method 1: Linear Regression of Price on combined textual description of product, Active ingredients, and Therapeutic Class

Method 2: Random Forest Regression of Price on combined textual description of product, Active ingredients, and Therapeutic Class

Method 3: Building a Neural Network with a single hidden layer
"""

# Splitting the Data into Train and Test sets
from sklearn.model_selection import train_test_split
random.seed(534)

train, test = train_test_split(medicines_final, test_size=0.2, random_state=534)

train

test

train['activeIngredient'].head(30)

!wget -c http://evexdb.org/pmresources/vec-space-models/PubMed-and-PMC-w2v.bin
!gzip -d BioWordVec_PubMed_MIMICIII_d200.txt.gz

#!pip install gensim

# Loading the BioWordVec Embeddings
from gensim.models import KeyedVectors
model = KeyedVectors.load_word2vec_format('PubMed-and-PMC-w2v.bin', binary=True)

medicines_final.isna().sum()

medicines_final.dropna(subset=['Combined_desc'], inplace=True)
medicines_final.dropna(subset=['therapeutic_class'], inplace=True)

medicines_final.isna().sum()

"""**AIM 1: Categorisation**

Creating functions to calculate average embeddings.
"""

from sklearn.metrics.pairwise import cosine_similarity
from gensim.utils import simple_preprocess

def textprocess(input_text):
    processed_text = simple_preprocess(input_text)

    processed_text = [word for word in processed_text if word in model.key_to_index]
    
    return processed_text

def textembeddings(data):
    text_embedding = []
    
    for element in data:
      processed = textprocess(str(element))
      embeddings = []
      
      for word in processed:
        embedding = model[word]
        embeddings.append(embedding)
      
      avg_embedding = np.mean(embeddings, axis=0)
      text_embedding.append(avg_embedding)
    return text_embedding

# Generating embeddings for Drug Category Descriptions
Drug_Category_Embeddings = textembeddings(drug_categories['Description'])

combined_input = medicines_final['Combined_desc'] + medicines_final['mechanismOfAction']
combined_input

ingredients = textembeddings(medicines_final['activeIngredient'])
combineddesc_medicines = textembeddings(combined_input)
therapeutic_class = textembeddings(medicines_final['therapeutic_class'])

"""AIM 1: Method 1 - Cosine Similarity between Medicine combined description and Drug Category Description.


"""

similarity_matrix = cosine_similarity(Drug_Category_Embeddings, combineddesc_medicines)

similarity_matrix.shape

medicines_results = medicines_final.copy()
closest_indices = np.argmax(similarity_matrix, axis=0)
medicines_results['DescriptionDistanceBasedCategories'] = closest_indices

medicines_results['DescriptionDistanceBasedCategories'] = closest_indices

index_to_category = dict(zip(drug_categories.index, drug_categories['Drug']))
medicines_results['DrugCategoryFromDescription'] = medicines_results['DescriptionDistanceBasedCategories'].apply(lambda x: index_to_category[x])

medicines_results

"""AIM 1: Method 2 - Perfroming K Means Clustering. (Comparison with Drug Categories done later)"""

ingredients_new = np.zeros((len(ingredients), 200))

for i, arr in enumerate(ingredients):
    ingredients_new[i, :] = arr

therapeutic_new = np.zeros((len(therapeutic_class), 200))

for i, arr in enumerate(therapeutic_class):
    therapeutic_new[i, :] = arr

concatenated_embeddings = np.concatenate((ingredients_new,np.stack(combineddesc_medicines),therapeutic_new), axis=1)
concatenated_embeddings2 = np.nan_to_num(concatenated_embeddings, nan=0)
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=40,max_iter=500)
kmeans.fit(concatenated_embeddings2)
labels = kmeans.labels_

medicines_results['KMeansClustersConcatenated'] = labels

medicines_results

nan_indices = np.isnan(concatenated_embeddings)
print(np.where(nan_indices))

np.where(nan_indices)[0]

concatenated_embeddings[132]

concatenated_embeddings[np.where(nan_indices)[0]]

"""AIM 1: Method 3 - Topic Modeling"""

import nltk
from gensim import corpora
from gensim.corpora import Dictionary
from gensim.models.ldamodel import LdaModel
from gensim.utils import simple_preprocess
nltk.download('stopwords')
from nltk.corpus import stopwords

stop_words = stopwords.words('english')
stop_words.extend(['medicine', 'doctor', 'symptoms', 'treatment', 'medicines', 'also', 'effects', 'tablet', 'take', 'helps','used','help'])

def tokenize(text):
    tokens = simple_preprocess(text)
    tokens = [token for token in tokens if token not in stop_words]
    return tokens

medicines_final['tokens'] = medicines_final['Combined_desc'].apply(lambda x: tokenize(x))
dict_tokens = Dictionary(medicines_final['tokens'])

corpus = [dict_tokens.doc2bow(doc) for doc in medicines_final['tokens']]
lda_model = LdaModel(corpus=corpus, id2word=dict_tokens, num_topics=40, random_state=567, iterations=800)

medicines_results['topic'] = [max(lda_model[doc], key=lambda x: x[1])[0] for doc in corpus]

top_words = []
for doc in corpus:
    topic = max(lda_model[doc], key=lambda x: x[1])[0]
    topic_words = lda_model.show_topic(topic, topn=20)
    top_words.append([word[0] for word in topic_words])

medicines_results['top_words'] = top_words

# Get the top 20 words for each topic
topics_words = lda_model.show_topics(num_topics=40, num_words=20, formatted=False)

topics_words[3][1]

Drug_Category_Embeddings = textembeddings(drug_categories['Description'])
similarity_matrix3 = cosine_similarity(Drug_Category_Embeddings, textembeddings(medicines_results['top_words']))
closest_indices3 = np.argmax(similarity_matrix3, axis=0)
medicines_results['topicmodellingsimilar'] = closest_indices3
medicines_results['DrugCategoryFromTopicModeling'] = medicines_results['topicmodellingsimilar'].apply(lambda x: index_to_category[x])

medicines_results

#TopicModelingVDescriptioncomparison = np.where((medicines_results['DrugCategoryFromDescription'] != medicines_results['DrugCategoryFromTopicModeling']))
#len(TopicModelingVDescriptioncomparison[0])

"""Analysing medicines for each category acc to classification by description similarities."""

grouped_descsimilarity = medicines_results['Name'].groupby(medicines_results['DrugCategoryFromDescription'])
grouped_descsimilarity.sum()

category_sets1 = medicines_results.groupby('DrugCategoryFromDescription')['Name'].unique()
category_sets2 = medicines_results.groupby('DrugCategoryFromTopicModeling')['Name'].unique()
category_sets3 = medicines_results.groupby('KMeansClustersConcatenated')['Name'].unique()

category_sets1

category_sets2

category_sets3

category_sets4 = medicines_results.groupby('KMeansClustersConcatenated')['Uses'].unique()

category_sets4[0]

len(category_sets4[0])

clustering_uses = {}
for i in range(0,len(category_sets4)):
  clustering_uses[i] = np.mean(np.array(textembeddings(category_sets4[i])),axis=0)

clustering_uses[0]

len(clustering_uses[0])

"""AIM 1: Method 3 - Performing Classification by omcparing cluster values to drug category descriptions via 'uses' aggregation for each cluster. """

clustering_values = list(clustering_uses.values())
clustering_values[7][np.isnan(clustering_values[7])] = 0
clustering_values[36][np.isnan(clustering_values[36])] = 0
clustering_values[32][np.isnan(clustering_values[32])] = 0

clustering_values[32]

interim = medicines_results['KMeansClustersConcatenated'].apply(lambda x: clustering_values[x])
list(interim)

similarity_matrix4 = cosine_similarity(Drug_Category_Embeddings, list(interim))
#similarity_matrix4 = cosine_similarity(Drug_Category_Embeddings, list(clustering_uses.values()))
closest_indices4 = np.argmax(similarity_matrix4, axis=0)
medicines_results['clusteringsimilar'] = closest_indices4
medicines_results['DrugCategoryFromClustering'] = medicines_results['clusteringsimilar'].apply(lambda x: index_to_category[x])

"""Dataset with results from all 3 Methods of Classification"""

medicines_results

"""Exploring difference/distance between drug category embeddings"""

from sklearn.metrics.pairwise import euclidean_distances

embeddings_array = np.array(Drug_Category_Embeddings)
euclidean_dist_matrix = euclidean_distances(embeddings_array)

euclidean_dist_matrix

import seaborn as sns

sns.heatmap(euclidean_dist_matrix, cmap="YlGnBu")
plt.xticks(range(40), drug_categories['Drug'], rotation=90)
plt.yticks(range(40), drug_categories['Drug'], rotation=0)
plt.show()

"""The more common drug category ailments, eg Cold Cures, are much closer to most other categories compared to ailments which are less common, eg Barbiturates. This also helps explain why these common ailments have more medicines classified within them. Since they are similar to all embeddings, medicines belonging to other categories may be classified as common ailment categories"""

from scipy.spatial.distance import euclidean

# assuming you have a dataframe called `medicines` with columns 'Category1', 'Category2', and 'Category3',
# and a list of embeddings called `Drug_Category_Embeddings`

def calculate_avg_euclidean_distance(row):
    # get the embeddings for each category
    category1_embedding = Drug_Category_Embeddings[row['DescriptionDistanceBasedCategories']]
    category2_embedding = Drug_Category_Embeddings[row['topicmodellingsimilar']]
    category3_embedding = Drug_Category_Embeddings[row['clusteringsimilar']]
    
    # calculate the euclidean distances
    distance1_2 = euclidean(category1_embedding, category2_embedding)
    distance1_3 = euclidean(category1_embedding, category3_embedding)
    distance2_3 = euclidean(category2_embedding, category3_embedding)
    
    # calculate the average distance and return it
    return (distance1_2 + distance1_3 + distance2_3) / 3

# create a new column called 'avgdistancemebeddings' and fill it with the average distances
medicines_results['avgdistancemebeddings'] = medicines_results.apply(calculate_avg_euclidean_distance, axis=1)
medicines_results['avgdistancemebeddings'].hist()

"""From the histogram above we notice that the average euclidean distance between the embeddings of the 3 categories for each medicine (one for each method) is normally distributed around 0.8 with a spike at 0-0.1, implying extremely similar categories from each method.

Analysing distribution of medicines by Categories for each of the three methods.
"""

categories = medicines_results['DrugCategoryFromDescription'].unique()
max_length = max(medicines_results['DrugCategoryFromDescription'].value_counts())

medicine_lists = []
for category in categories:
    medicines_in_category = medicines_results.loc[medicines_results['DrugCategoryFromDescription'] == category]['Name'].tolist()
    medicine_list = medicines_in_category + [np.nan]*(max_length-len(medicines_in_category))
    medicine_lists.append(medicine_list)

category_DescriptionDistance = pd.DataFrame(medicine_lists).T
category_DescriptionDistance.fillna('', inplace=True)
category_DescriptionDistance.columns = categories

categories2 = medicines_results['DrugCategoryFromTopicModeling'].unique()
max_length2 = max(medicines_results['DrugCategoryFromTopicModeling'].value_counts())

medicine_lists = []
for category in categories2:
    medicines_in_category = medicines_results.loc[medicines_results['DrugCategoryFromTopicModeling'] == category]['Name'].tolist()
    medicine_list = medicines_in_category + [np.nan]*(max_length2-len(medicines_in_category))
    medicine_lists.append(medicine_list)

category_TopicModeling = pd.DataFrame(medicine_lists).T
category_TopicModeling.fillna('', inplace=True)
category_TopicModeling.columns = categories2

categories3 = medicines_results['DrugCategoryFromClustering'].unique()
max_length3 = max(medicines_results['DrugCategoryFromClustering'].value_counts())

medicine_lists = []
for category in categories3:
    medicines_in_category = medicines_results.loc[medicines_results['DrugCategoryFromClustering'] == category]['Name'].tolist()
    medicine_list = medicines_in_category + [np.nan]*(max_length3-len(medicines_in_category))
    medicine_lists.append(medicine_list)

category_Clustering = pd.DataFrame(medicine_lists).T
category_Clustering.fillna('', inplace=True)
category_Clustering.columns = categories3

pd.set_option('display.max_columns', None)
category_Clustering.head(50)

merged_df = pd.concat([category_DescriptionDistance, category_TopicModeling, category_Clustering], axis=0)
#avg_medicines_per_category = merged_df.groupby(merged_df.columns, axis=0).count().mean()
merged_df

plt.bar(merged_df.nunique().sort_values().index, (merged_df.nunique().sort_values().values)/3)
#plt.bar(merged_df.nunique().index, (merged_df.nunique().values)/3)
plt.xticks(rotation=90)
plt.xlabel('Column Names')
plt.ylabel('Number of Unique Values')
plt.show()

"""The graph above provides an approximation of medicines distribution by category."""

print(len(medicines_results['DrugCategoryFromClustering'].value_counts()))
print(len(medicines_results['DrugCategoryFromDescription'].value_counts()))
print(len(medicines_results['DrugCategoryFromTopicModeling'].value_counts()))

print(len(medicines_results['DrugCategoryFromDescription'].unique()))
print(len(medicines_results['DrugCategoryFromTopicModeling'].unique()))
print(len(medicines_results['DrugCategoryFromTopicModeling'].unique()))

"""Not all Drug Categories were present in the final classification results from any of the three methods

**AIM 2: Price Modeling**
"""

from sklearn.linear_model import LinearRegression
medicines_final_copy = medicines_final.copy()

#For each word, the function checks if it is present in the pre-trained KeyedVectors model. If the word is present, the function retrieves its corresponding word embedding and appends it to the list.
def bio_embedding(text):
  embed = []
  for word in text.split():
    if word in model:
      embed.append(model[word])
  if len(embed) == 0:
        return np.zeros(model.vector_size)
  else:
        return np.mean(embed, axis=0)

medicines_final_copy.head()

medicines_final_copy.isna().sum()

medicines_final_copy['therapeutic_class'] = medicines_final_copy['therapeutic_class'].fillna('unknown')
medicines_final_copy['Combined_desc'] = medicines_final_copy['Combined_desc'].fillna('unknown')
# There were NA values, which were throwing errors(considering it as float) while creating the embeddings so filled the na values
medicines_final_copy['Price'] = medicines_final_copy['Price'].fillna(medicines_final_copy['Price'].mean())

medicines_final_copy['Combined_desc_embed'] = medicines_final_copy['Combined_desc'].apply(bio_embedding)
medicines_final_copy['activeIngredient_embed'] = medicines_final_copy['activeIngredient'].apply(bio_embedding)
medicines_final_copy['therapeutic_class_embed'] = medicines_final_copy['therapeutic_class'].apply(bio_embedding)

# Combine the embeddings into a single feature matrix
X_embed = np.hstack((np.vstack(medicines_final_copy['Combined_desc_embed'].values),
                     np.vstack(medicines_final_copy['activeIngredient_embed'].values),
                     np.vstack(medicines_final_copy['therapeutic_class_embed'].values)))

X_embed.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_std = scaler.fit_transform(X_embed)

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

pca = PCA(n_components=100)
X_pca = pca.fit_transform(X_std)
y = medicines_final_copy['Price']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

"""Linear Regression"""

# Creating an instance of LR
LRmodel = LinearRegression() 

# Fitting the LR model
LRmodel.fit(X_train, y_train)

# Prediction on test set
y_pred = LRmodel.predict(X_test)

# Calculating the score
score = LRmodel.score(X_test, y_test)

#Printing the R2
print(f'R^2 score: {score:.2f}')

"""Random Forest"""

from sklearn.ensemble import RandomForestRegressor

# Creating an instance for RF
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Fitting the model 
rf_model.fit(X_train, y_train)

# Prediction on test set
y_pred = rf_model.predict(X_test)

#Calculating OOS R2
score = rf_model.score(X_test, y_test)
print(f'R^2 score: {score:.2f}')

"""Neural Network"""

from sklearn.neural_network import MLPRegressor
from sklearn.metrics import r2_score

# Creating an instance for Multi Layer Perceptron, with 300 neurons in the hidden layer, relu as the activation function and alpha = 0.001
mlp = MLPRegressor(hidden_layer_sizes=(300,), activation='relu', alpha=0.001)

# Fitting MLP
mlp.fit(X_train, y_train)

# Prediction on test set
y_pred = mlp.predict(X_test)

#Calculating OOS R2
r2 = r2_score(y_test, y_pred)

print(f'R-squared: {r2:.2f}')

"""**AIM 3: Substitution**"""

#Aim 3: Predict the substitute of a medicine basis product information, description and benifits

##creating an index column (first resetting it)
medicines_final_copy = medicines_final_copy.reset_index(drop=True)

## calculating the similarity between medicine
med_similarity_matrix = cosine_similarity(combineddesc_medicines, combineddesc_medicines)

## getting index of 6 most similar medicines (as the first is likely to be itself)
sim_index = np.argsort(med_similarity_matrix,axis=1)[:,-1:-7:-1]

#storing the indices in a dataframe
df_sim_index = pd.DataFrame(sim_index, columns = ['Sim0','Sim1','Sim2','Sim3','Sim4','Sim5'])

## adding columns with substitute index
medicines_final_copy['Sim0']=df_sim_index['Sim0']
medicines_final_copy['Sim1']=df_sim_index['Sim1']
medicines_final_copy['Sim2']=df_sim_index['Sim2']
medicines_final_copy['Sim3']=df_sim_index['Sim3']
medicines_final_copy['Sim4']=df_sim_index['Sim4']
medicines_final_copy['Sim5']=df_sim_index['Sim5']

medicines_final_copy['index'] = range(0,len(medicines_final_copy.index))

medicines_final_copy

## getting the index of first substitute
medicines_final_copy['Sub1']=np.where(medicines_final_copy['Sim0']==medicines_final_copy['index'],medicines_final_copy['Sim1'],medicines_final_copy['Sim0'])

# appending details of the substitute medicine with the primary medicine
index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['Name']))
medicines_final_copy['Sub1_Name'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])
# index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['id']))
# medicines_final_copy['Sub1_id'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])
# index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['manufacturer']))
# medicines_final_copy['Sub1_manufacturer'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])
index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['Price']))
medicines_final_copy['Sub1_Price'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])
index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['therapeutic_class']))
medicines_final_copy['Sub1_therapeutic_class'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])

index_to_category = dict(zip(medicines_final_copy.index, medicines_final_copy['dosageForm']))
medicines_final_copy['Sub1_dosageForm'] = medicines_final_copy['Sub1'].apply(lambda x: index_to_category[x])

medicines_sub = medicines_final_copy[['dosageForm', 'Name', 'Price', 'therapeutic_class','Sub1','Sub1_Name','Sub1_Price','Sub1_therapeutic_class','Sub1_dosageForm']]
np.where(medicines_sub['therapeutic_class']==medicines_sub['Sub1_therapeutic_class'],1,0).sum()/len(medicines_sub)
np.where(medicines_sub['dosageForm']==medicines_sub['Sub1_dosageForm'],1,0).sum()/len(medicines_sub)

medicines_sub.head(100)

#We observe that the for a given medicine, we are able to predict a substitute with the same therapeutic_class, having the same benifits.